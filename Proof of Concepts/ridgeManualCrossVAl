import math

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures

DATASET_PATH = "Data/dublinbikes_20200101_20200401.csv"
SELECTED_STATIONS = [19, 10, 96]


def plot_station_data(time_full_days, y_available_bikes, station_id):
    # plot number of available bikes at station id vs number of days
    plt.rc("font", size=18)
    plt.rcParams["figure.constrained_layout.use"] = True
    plt.figure(figsize=(8, 8), dpi=80)
    # plt.plot(time_full_days, y_available_bikes, '-o')
    plt.scatter(time_full_days, y_available_bikes, color="red", marker=".")
    plt.xlabel("Time (Days)")
    plt.ylabel(f"Available Bikes at Station {station_id}")
    plt.title(f"Available bikes vs Days for bike station {station_id}")
    plt.show()


def plot_preds(time_full_days, y_available_bikes, time_preds_days, y_pred, station_id):
    plt.scatter(time_full_days, y_available_bikes, color="black")
    plt.scatter(time_preds_days, y_pred, color="blue")
    plt.xlabel("Time (days)")
    plt.ylabel(f"Available Bikes at Station {station_id}")
    plt.title(f"Available bikes vs predicted available bikes ")
    plt.legend(["training data", "predictions"], loc="upper right")
    plt.show()


def predidct_available_bikes_seasonality(
    model,
    q_step_ahead,
    seasonality,
    lag,
    y_available_bikes,
    time_full_days,
    time_sampling_interval_dt,
    plot,
    station_id,
    trend,
    print_flag,
):
    # q_step_ahead-step ahead prediction
    stride = 1
    XX_input_features = y_available_bikes[
        0 : y_available_bikes.size - q_step_ahead - lag * seasonality : stride
    ]

    for i in range(1, lag):
        X = y_available_bikes[
            i * seasonality : y_available_bikes.size
            - q_step_ahead
            - (lag - i) * seasonality : stride
        ]
        XX_input_features = np.column_stack((XX_input_features, X))

    yy_outputs_available_bikes = y_available_bikes[
        lag * seasonality + q_step_ahead :: stride
    ]
    time_for_each_prediction_in_days = time_full_days[
        lag * seasonality + q_step_ahead :: stride
    ]

    train, test = train_test_split(
        np.arange(0, yy_outputs_available_bikes.size), test_size=0.2
    )

    model_info = model.fit(XX_input_features[train], yy_outputs_available_bikes[train])
    if print_flag:
        print(model_info.intercept_, model_info.coef_)

    y_pred = model_info.predict(XX_input_features)

    mse = mean_squared_error(
        yy_outputs_available_bikes[test],
        model_info.predict(XX_input_features[test]),
        multioutput="uniform_average",
        squared=True,
    )
    print(f"Ridge MSE: {mse}")

    if plot:
        plt.rc("font", size=18)
        plt.rcParams["figure.constrained_layout.use"] = True
        plt.scatter(time_full_days, y_available_bikes, color="black")
        plt.scatter(time_for_each_prediction_in_days, y_pred, color="blue")
        plt.xlabel("Time (days)")
        plt.ylabel(f"Available Bikes at Station {station_id}")
        plt.title(f"Available bikes vs predicted available bikes using {trend}")
        plt.legend(["training data", "predictions"], loc="upper right")
        num_samples_per_day = math.floor(24 * 60 * 60 / time_sampling_interval_dt)
        # plt.xlim(((lag*seasonality+q_step_ahead)/num_samples_per_day,(lag*seasonality+q_step_ahead)/num_samples_per_day+10))
        plt.show()


def test_various_seasonaliy_preds(
    test_model, y_available_bikes, time_full_days, time_sampling_interval_dt, station_id
):
    plot = True
    print_flag = True
    # prediction using short-term trend
    predidct_available_bikes_seasonality(
        model=test_model,
        q_step_ahead=10,
        seasonality=1,
        lag=3,
        y_available_bikes=y_available_bikes,
        time_full_days=time_full_days,
        time_sampling_interval_dt=time_sampling_interval_dt,
        plot=plot,
        station_id=station_id,
        trend="Short Term Trend",
        print_flag=print_flag,
    )

    # prediction using daily seasonality
    d = math.floor(
        24 * 60 * 60 / time_sampling_interval_dt
    )  # number of samples per day
    predidct_available_bikes_seasonality(
        model=test_model,
        q_step_ahead=2,
        seasonality=d,
        lag=3,
        y_available_bikes=y_available_bikes,
        time_full_days=time_full_days,
        time_sampling_interval_dt=time_sampling_interval_dt,
        plot=plot,
        station_id=station_id,
        trend="Daily Seasonality",
        print_flag=print_flag,
    )

    # prediction using weekly seasonality
    w = math.floor(
        7 * 24 * 60 * 60 / time_sampling_interval_dt
    )  # number of samples per day
    predidct_available_bikes_seasonality(
        model=test_model,
        q_step_ahead=2,
        seasonality=w,
        lag=3,
        y_available_bikes=y_available_bikes,
        time_full_days=time_full_days,
        time_sampling_interval_dt=time_sampling_interval_dt,
        plot=plot,
        station_id=station_id,
        trend="Weekly Seasonality",
        print_flag=print_flag,
    )


def feature_engineering(
    q_step_size,
    lag,
    stride,
    y_available_bikes,
    time_full_days,
    time_sampling_interval_dt,
):
    # number of samples per day
    num_samples_per_day = math.floor(24 * 60 * 60 / time_sampling_interval_dt)
    # number of samples per week
    num_samples_per_week = math.floor(7 * 24 * 60 * 60 / time_sampling_interval_dt)

    len = (
        y_available_bikes.size
        - num_samples_per_week
        - lag * num_samples_per_week
        - q_step_size
    )
    XX_input_features = y_available_bikes[q_step_size : q_step_size + len : stride]

    for i in range(1, lag):
        X = y_available_bikes[
            i * num_samples_per_week
            + q_step_size : i * num_samples_per_week
            + q_step_size
            + len : stride
        ]
        XX_input_features = np.column_stack((XX_input_features, X))

    for i in range(0, lag):
        X = y_available_bikes[
            i * num_samples_per_day
            + q_step_size : i * num_samples_per_day
            + q_step_size
            + len : stride
        ]
        XX_input_features = np.column_stack((XX_input_features, X))

    # for i in range(0, lag):
    #     X = y_available_bikes[i : i + len : stride]
    #     XX_input_features = np.column_stack((XX_input_features, X))

    yy_outputs_available_bikes = y_available_bikes[
        lag * num_samples_per_week
        + num_samples_per_week
        + q_step_size : lag * num_samples_per_week
        + num_samples_per_week
        + q_step_size
        + len : stride
    ]
    time_for_each_prediction_in_days = time_full_days[
        lag * num_samples_per_week
        + num_samples_per_week
        + q_step_size : lag * num_samples_per_week
        + num_samples_per_week
        + q_step_size
        + len : stride
    ]

    return (
        XX_input_features,
        yy_outputs_available_bikes,
        time_for_each_prediction_in_days,
    )

def PolynomialOrderCrossValidation(XX, yy):
    kf = KFold(n_splits=10)
    mean_error = []
    std_error = []
    q_range = [1, 2, 3, 4, 5]
    for q in q_range:
        Xpoly = PolynomialFeatures(q).fit_transform(XX)
        model_ridge = Ridge()
        temp = []
        for train, test in kf.split(XX):
            model_ridge.fit(Xpoly[train], yy[train])
            ypred = model_ridge.predict(Xpoly[test])
            temp.append(mean_squared_error(yy[test], ypred))
        mean_error.append(np.array(temp).mean())
        std_error.append(np.array(temp).std())
    plt.rc("font", size=18)
    plt.rcParams["figure.constrained_layout.use"] = True
    plt.errorbar(q_range, mean_error, yerr=std_error, linewidth=3)
    plt.xlabel("q")
    plt.ylabel("Mean square error")
    plt.title("Ridge Regression Cross Validation Results: Polynomial Feature q")
    plt.show()

# Using 5 fold cross validation to find the optimal C value for Ridge regression
def RidgeAlphaValueCrossValidation(X, y_regression):
    mean_error = []
    std_error = []
    Ci_range = [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000]
    for Ci in Ci_range:
        ridge_model = Ridge(alpha=1/(2*Ci))
        temp = []
        kf = KFold(n_splits=5)
        for train, test in kf.split(X):
            ridge_model.fit(X[train], y_regression[train])
            ypred = ridge_model.predict(X[test])
            temp.append(mean_squared_error(y_regression[test], ypred))
        mean_error.append(np.array(temp).mean())
        std_error.append(np.array(temp).std())
    plt.rc("font", size=18)
    plt.rcParams["figure.constrained_layout.use"] = True
    mean_error = np.array(mean_error)
    std_error = np.array(std_error)
    plt.errorbar(Ci_range, mean_error, yerr=std_error)
    plt.xlabel("Ci")
    plt.ylabel("Mean square error")
    plt.title("Ridge Regression Cross Validation for wide range of Ci")
    # plt.xlim((0, 200))
    plt.show()


def ridgeRegression(X, y, C):
    #  alpha = 1/2C for ridge regression.
    alpha = 1/(2*C)
    ridge_model = Ridge(alpha=alpha)
    ridge_model.fit(X, y)
    print(f'\nRidge regression model C Value= {C}, Alpha Value= {alpha}')
    print(f'Ridge regression model intercept θ0 = {ridge_model.intercept_}')
    print(f'Ridge regression model slope θ1 - θ21  = {ridge_model.coef_} \n')
    return ridge_model

def exam_2021(df_station, station_id):
    # converting timestamp to unix timestamp in seconds
    time_full_seconds = (
        pd.array(pd.DatetimeIndex(df_station.iloc[:, 1]).astype(np.int64)) / 1000000000
    )
    time_full_seconds = time_full_seconds.to_numpy()
    time_sampling_interval_dt = time_full_seconds[1] - time_full_seconds[0]
    print(
        f"data sampling interval is {time_sampling_interval_dt} secs or {time_sampling_interval_dt/60} minutes"
    )

    time_full_days = (
        (time_full_seconds - time_full_seconds[0]) / 60 / 60 / 24
    )  # convert timestamp to days
    y_available_bikes = np.extract([time_full_seconds], df_station.iloc[:, 6]).astype(
        np.int64
    )

    # plot extracted data
    plot_station_data(time_full_days, y_available_bikes, station_id)

    test_model_ridge = Ridge(fit_intercept=False)
    test_various_seasonaliy_preds(
        test_model_ridge,
        y_available_bikes,
        time_full_days,
        time_sampling_interval_dt,
        station_id,
    )

    XX, yy, time_preds_days = feature_engineering(
        q_step_size=2,
        lag=3,
        stride=1,
        y_available_bikes=y_available_bikes,
        time_full_days=time_full_days,
        time_sampling_interval_dt=time_sampling_interval_dt,
    )

    scaler = MinMaxScaler()
    XX_scaled = scaler.fit_transform(XX)

   # Polynomial Order Cross Validation for Ridge Regression
    PolynomialOrderCrossValidation(XX_scaled,yy)
    polynomial_order_ridge = int(input("Please enter the polynomial order for Ridge Regression 'q' value:    "))
    
    XX_polynomial = XX
    if polynomial_order_ridge > 1:
        XX_polynomial = PolynomialFeatures(polynomial_order_ridge).fit_transform(XX_scaled)

    RidgeAlphaValueCrossValidation(XX_polynomial, yy)
    C_value_ridge = int(
        input("Please choose the desired 'C' value for the Ridge Regression model:    ")
    )

    train, test = train_test_split(np.arange(0, yy.size), test_size=0.2)

    ridge_regression_model_C_0_01 = ridgeRegression(
        XX_polynomial[train], yy[train], 0.01)
    ridge_regression_model_C_0_1 = ridgeRegression(
        XX_polynomial[train], yy[train], 0.1)
    ridge_regression_model_C_1 = ridgeRegression(XX_polynomial[train], yy[train], 1)
    ridge_regression_model_C_10 = ridgeRegression(
        XX_polynomial[train], yy[train], 10)
    ridge_regression_model_C_100 = ridgeRegression(
        XX_polynomial[train], yy[train], 100)
    ridge_regression_model_C_1000 = ridgeRegression(
        XX_polynomial[train], yy[train], 1000)
    ridge_regression_model_C_10000 = ridgeRegression(
        XX_polynomial[train], yy[train], 10000)
    ridge_regression_model_C_100000 = ridgeRegression(
        XX_polynomial[train], yy[train], 100000)

    ypred_ridge_C_0_01 = ridge_regression_model_C_0_01.predict(XX_polynomial[test])
    ypred_ridge_C_0_1 = ridge_regression_model_C_0_1.predict(XX_polynomial[test])
    ypred_ridge_C_1 = ridge_regression_model_C_1.predict(XX_polynomial[test])
    ypred_ridge_C_10 = ridge_regression_model_C_10.predict(XX_polynomial[test])
    ypred_ridge_C_100 = ridge_regression_model_C_100.predict(XX_polynomial[test])
    ypred_ridge_C_1000 = ridge_regression_model_C_1000.predict(XX_polynomial[test])
    ypred_ridge_C_10000 = ridge_regression_model_C_10000.predict(XX_polynomial[test])
    ypred_ridge_C_100000 = ridge_regression_model_C_100000.predict(XX_polynomial[test])

    ypred = [ypred_ridge_C_0_01, ypred_ridge_C_0_1, ypred_ridge_C_1, ypred_ridge_C_10,
             ypred_ridge_C_100, ypred_ridge_C_1000, ypred_ridge_C_10000, ypred_ridge_C_100000]


    cValue = 0.01
    for y in ypred:
        print(f'c is {cValue}')
        mse = mean_squared_error(
        yy[test],
        y,
        multioutput="uniform_average",
        squared=True,
    )
        print(f"All seasonality Ridge MSE: {mse}")
        cValue *= 10

   
    train, test = train_test_split(np.arange(0, yy.size), test_size=0.2)

    model = Ridge(fit_intercept=False).fit(XX[train], yy[train])
    print(model.intercept_, model.coef_)
    y_pred = model.predict(XX)

    mse = mean_squared_error(
        yy[test],
        model.predict(XX[test]),
        multioutput="uniform_average",
        squared=True,
    )
    print(f"All seasonality Ridge MSE: {mse}")
    plot_preds(time_full_days, y_available_bikes, time_preds_days, y_pred, station_id)


def main():
    df_dublin_bikes = pd.read_csv(DATASET_PATH)
    df_dublin_bikes["TIME"] = pd.to_datetime(df_dublin_bikes["TIME"])
    df_dublin_bikes.rename(columns={"STATION ID": "STATION_ID"}, inplace=True)
    for station in SELECTED_STATIONS:
        # station_id = df_dublin_bikes.STATION_ID == station
        # df_station = df_dublin_bikes[station_id]
        df_station = df_dublin_bikes.loc[df_dublin_bikes["STATION_ID"] == station]
        exam_2021(df_station, station)
        break


if __name__ == "__main__":
    main()

# TODO:
# do model features mean square error -> ss/ ss+d/ ss+w/ d/ d+w/ w 
# selecting lag cross validation i.e how many points before
# Ridge alpha value cross validation
# kNN_k_value_finder cross validation
# Train models using cross validation
# Dummy Model -> predicting same point as the last is better idea


# NOTE:
# let the data help tell you which features are important 
# e.g. by fitting a linear model and looking at the weights given to each feature and/or by progressively adding/removing features 
# to see the impact on predictions.
# When using linear models its often worth looking at use of augmented features e.g. polynomials (but not just that).   


